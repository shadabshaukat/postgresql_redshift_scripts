\! echo '#### Cluster'
SELECT type ,node ,SUM(used_gb) used_gb ,SUM(capacity_gb) capacity_gb ,ROUND((SUM(used_gb) / SUM(capacity_gb)) * 100, 1) pct_used FROM ( SELECT CASE capacity WHEN 380319 THEN 'dc1.8xlarge' WHEN 760956 THEN 'dc2.8xlarge' WHEN 190633 THEN CASE WHEN mount LIKE '/dev/nvme%' THEN 'dc2.large' ELSE 'dc1.large' END WHEN 952455 THEN 'ds2.xlarge' WHEN 945026 THEN 'ds2.8xlarge' ELSE NULL END AS type ,OWNER "node" ,diskno "disk" ,ROUND(CAST(used - tossed AS NUMERIC) / 1024, 1) AS used_gb ,CASE capacity WHEN 380319 THEN 320 WHEN 760956 THEN 640 WHEN 190633 THEN 160 WHEN 952455 THEN 666 WHEN 945026 THEN 666 ELSE NULL END AS capacity_gb ,ROUND( (CAST(used-tossed AS NUMERIC) /CASE WHEN capacity > 0 THEN CAST( (CASE capacity WHEN 380319 THEN 320 WHEN 760956 THEN 640 WHEN 190633 THEN 160 WHEN 952455 THEN 666 WHEN 945026 THEN 666 ELSE NULL END * 1024) AS NUMERIC) ELSE 1 END ) * 100, 1) AS pct_used FROM stv_partitions WHERE OWNER = host ORDER BY OWNER ,host ,diskno ) t GROUP BY 1 ,2 ORDER BY 1 ,2;
\! echo '#### Schemas'
SELECT TRIM(db_name) AS db_name ,TRIM(schema_name) AS schema_name ,TO_CHAR(SUM(rows_total),'999,999,999,999') rows_total ,TO_CHAR(SUM(COALESCE(size_in_gb,0)),'999,999,999,999') size_in_gb FROM (SELECT id table_id ,datname db_name ,nspname schema_name ,relname table_name ,SUM(rows) rows_total ,SUM(sorted_rows) rows_sorted FROM stv_tbl_perm JOIN pg_class ON pg_class.oid = stv_tbl_perm.id JOIN pg_namespace ON pg_namespace.oid = relnamespace JOIN pg_database ON pg_database.oid = stv_tbl_perm.db_id WHERE name NOT LIKE 'pg_%' AND name NOT LIKE 'stl_%' AND name NOT LIKE 'stp_%' AND name NOT LIKE 'padb_%' AND nspname <> 'pg_catalog' GROUP BY id, datname, nspname, relname ORDER BY id, datname, nspname, relname) tbl_det LEFT JOIN (SELECT tbl table_id ,ROUND(CONVERT(REAL,COUNT(*))/1024,2) size_in_gb FROM stv_blocklist bloc GROUP BY tbl) tbl_size ON tbl_size.table_id = tbl_det.table_id GROUP BY 1,2 ORDER BY size_in_gb DESC;
\! echo '#### Large Tables'
SELECT database, schema, "table", encoded, diststyle, sortkey1, max_varchar, sortkey1_enc, sortkey_num, TO_CHAR(size,'999,999,999,999') size, pct_used, empty, unsorted, stats_off, TO_CHAR(tbl_rows,'999,999,999,999') tbl_rows, skew_sortkey1, skew_rows FROM svv_table_info ORDER BY size desc LIMIT 25;
\! echo '#### Skewed Tables'
SELECT database, schema, "table", encoded, diststyle, sortkey1, max_varchar, sortkey1_enc, sortkey_num, TO_CHAR(size,'999,999,999,999') size, pct_used, empty, unsorted, stats_off, TO_CHAR(tbl_rows,'999,999,999,999') tbl_rows, skew_sortkey1, skew_rows FROM svv_table_info WHERE skew_rows > 1.5 ORDER BY size desc LIMIT 25;
\! echo '#### Candidates for DISTSTYLE ALL'
SELECT database, schema, "table", encoded, diststyle, sortkey1, max_varchar, sortkey1_enc, sortkey_num, TO_CHAR(size,'999,999,999,999') size, pct_used, empty, unsorted, stats_off, TO_CHAR(tbl_rows,'999,999,999,999') tbl_rows, skew_sortkey1, skew_rows, (tbl_rows :: NUMERIC / size :: NUMERIC) rows_per_mb FROM  svv_table_info WHERE (tbl_rows :: NUMERIC / size :: NUMERIC) < 100 AND tbl_rows < 1000000 ORDER BY /*(tbl_rows::NUMERIC/size::NUMERIC)*/ size desc  LIMIT 25 ;
/*
\! echo '#### Potential Savings from DISTSTYLE ALL' TODO: Use system column count and node counts in place of hard coded.
SELECT database , schema , COUNT( * ) table_count , SUM( tbl_rows ) total_rows , SUM( size ) current_size , SUM( size ) / 32 new_size , SUM( size ) - (SUM( size ) / 32) potential_savings FROM svv_table_info WHERE (tbl_rows :: NUMERIC / size :: NUMERIC) < 100 AND tbl_rows < 1000000 GROUP BY database, schema ORDER BY potential_savings DESC ;
*/
\! echo '#### Alerts'
SELECT trim(s.perm_table_name) AS TABLE ,(sum(abs(datediff(seconds, coalesce(b.starttime, d.starttime, s.starttime), CASE WHEN coalesce(b.endtime, d.endtime, s.endtime) > coalesce(b.starttime, d.starttime, s.starttime) THEN coalesce(b.endtime, d.endtime, s.endtime) ELSE coalesce(b.starttime, d.starttime, s.starttime) END))) / 60)::NUMERIC(24, 0) AS minutes ,sum(coalesce(b.rows, d.rows, s.rows)) AS rows ,trim(split_part(l.event, ':', 1)) AS event ,substring(trim(l.solution), 1, 60) AS solution ,max(l.query) AS sample_query ,count(DISTINCT l.query) FROM stl_alert_event_log AS l LEFT JOIN stl_scan AS s ON s.query = l.query AND s.slice = l.slice AND s.segment = l.segment LEFT JOIN stl_dist AS d ON d.query = l.query AND d.slice = l.slice AND d.segment = l.segment LEFT JOIN stl_bcast AS b ON b.query = l.query AND b.slice = l.slice AND b.segment = l.segment WHERE l.userid > 1 AND l.event_time >= dateadd(day, - 7, CURRENT_DATE) GROUP BY 1 ,4 ,5 ORDER BY 2 DESC ,6 DESC LIMIT 15;
\! echo '#### Unused Tables'
SELECT database ,schema ,"table" ,size ,sortkey1 ,NVL(s.num_qs, 0) num_queries FROM svv_table_info t LEFT JOIN (SELECT tbl ,perm_table_name ,COUNT(DISTINCT query) num_qs FROM stl_scan s WHERE s.userid > 1 AND s.perm_table_name NOT IN ('Internal Worktable','S3') GROUP BY 1,2 ) s ON s.tbl = t.table_id WHERE NVL(s.num_qs, 0) = 0 ORDER BY size DESC LIMIT 25;
\! echo '#### Usage Pattern'
WITH profile AS ( SELECT database ,CASE WHEN "userid" = 1 THEN 'SYSTEM' WHEN REGEXP_INSTR("querytxt",'(padb_|pg_internal)' ) THEN 'SYSTEM' WHEN REGEXP_INSTR("querytxt",'[uU][nN][dD][oO][iI][nN][gG] ') THEN 'ROLLBACK' WHEN REGEXP_INSTR("querytxt",'[cC][uU][rR][sS][oO][rR] ' ) THEN 'CURSOR' WHEN REGEXP_INSTR("querytxt",'[fF][eE][tT][cC][hH] ' ) THEN 'CURSOR' WHEN REGEXP_INSTR("querytxt",'[dD][eE][lL][eE][tT][eE] ' ) THEN 'DELETE' WHEN REGEXP_INSTR("querytxt",'[cC][oO][pP][yY] ' ) THEN 'COPY' WHEN REGEXP_INSTR("querytxt",'[uU][pP][dD][aA][tT][eE] ' ) THEN 'UPDATE' WHEN REGEXP_INSTR("querytxt",'[iI][nN][sS][eE][rR][tT] ' ) THEN 'INSERT' WHEN REGEXP_INSTR("querytxt",'[vV][aA][cC][uU][uU][mM][ :]' ) THEN 'VACUUM' WHEN REGEXP_INSTR("querytxt",'[sS][eE][lL][eE][cC][tT] ' ) THEN 'SELECT' ELSE 'OTHER' END query_type ,DATEPART(hour, starttime) query_hour ,ROUND(SUM(DATEDIFF(milliseconds, starttime, endtime))::NUMERIC/1000,1) query_duration ,COUNT(*) query_total FROM stl_query WHERE endtime >= DATEADD(day, -7, CURRENT_DATE) GROUP BY 1,2,3 ) SELECT database, query_hour ,MAX(CASE WHEN query_type ='SELECT' THEN query_total ELSE NULL END) AS "select_count" ,MAX(CASE WHEN query_type ='SELECT' THEN query_duration ELSE NULL END) AS "select_duration" ,MAX(CASE WHEN query_type ='CURSOR' THEN query_total ELSE NULL END) AS "cursor_count" ,MAX(CASE WHEN query_type ='CURSOR' THEN query_duration ELSE NULL END) AS "cursor_duration" ,MAX(CASE WHEN query_type ='COPY' THEN query_total ELSE NULL END) AS "copy_count" ,MAX(CASE WHEN query_type ='COPY' THEN query_duration ELSE NULL END) AS "copy_duration" ,MAX(CASE WHEN query_type ='INSERT' THEN query_total ELSE NULL END) AS "insert_count" ,MAX(CASE WHEN query_type ='INSERT' THEN query_duration ELSE NULL END) AS "insert_duration" ,MAX(CASE WHEN query_type ='UPDATE' THEN query_total ELSE NULL END) AS "update_count" ,MAX(CASE WHEN query_type ='UPDATE' THEN query_duration ELSE NULL END) AS "update_duration" ,MAX(CASE WHEN query_type ='DELETE' THEN query_total ELSE NULL END) AS "delete_count" ,MAX(CASE WHEN query_type ='DELETE' THEN query_duration ELSE NULL END) AS "delete_duration" ,MAX(CASE WHEN query_type ='VACUUM' THEN query_total ELSE NULL END) AS "vacuum_count" ,MAX(CASE WHEN query_type ='VACUUM' THEN query_duration ELSE NULL END) AS "vacuum_duration" FROM profile GROUP BY 1,2 ORDER BY 1,2 ;
\! echo '#### Top 50 Queries'
SELECT TRIM("database") AS DB, COUNT(query) AS n_qry, MAX(SUBSTRING(qrytext, 1, 120)) AS qrytext, MIN(run_seconds) AS min_seconds, MAX(run_seconds) AS max_seconds, AVG(run_seconds) AS avg_seconds, SUM(run_seconds) AS total_seconds, MAX(query) AS max_query_id, MAX(starttime)::date AS last_run, aborted, MAX(mylabel) qry_label, TRIM(DECODE(event & 1, 1, 'Sortkey ', '') || DECODE(event & 2, 2, 'Deletes ', '') || DECODE(event & 4, 4, 'NL ', '') || DECODE(event & 8, 8, 'Dist ', '') || DECODE(event & 16, 16, 'Broacast ', '') || DECODE(event & 32, 32, 'Stats ', '')) AS Alert FROM (SELECT userid, label, stl_query.query, TRIM(DATABASE) AS DATABASE, NVL(qrytext_cur.text, TRIM(querytxt)) AS qrytext, MD5(NVL(qrytext_cur.text, TRIM(querytxt))) AS qry_md5, starttime, endtime, DATEDIFF(seconds, starttime, endtime)::NUMERIC(12,2) AS run_seconds, aborted, event, stl_query.label AS mylabel FROM stl_query LEFT OUTER JOIN (SELECT query, SUM(DECODE(TRIM(SPLIT_PART(event, ':', 1) ), 'Very selective query filter', 1, 'Scanned a large number of deleted rows' , 2, 'Nested Loop Join in the query plan' , 4, 'Distributed a large number of rows across the network', 8, 'Broadcasted a large number of rows across the network', 16, 'Missing query planner statistics', 32, 0)) AS event FROM stl_alert_event_log WHERE event_time >= DATEADD(day, -7, CURRENT_DATE) GROUP BY query) AS alrt ON alrt.query = stl_query.query LEFT OUTER JOIN (SELECT ut.xid, TRIM(SUBSTRING (text FROM STRPOS(UPPER( text), 'SELECT')) ) AS TEXT FROM stl_utilitytext ut WHERE sequence = 0 AND UPPER(text) LIKE 'DECLARE%' GROUP BY text, ut.xid) qrytext_cur ON ( stl_query.xid = qrytext_cur.xid ) WHERE userid <> 1 AND starttime >= DATEADD(day, -2, CURRENT_DATE)) GROUP BY DATABASE, userid, label, qry_md5, aborted, event ORDER BY total_seconds DESC LIMIT 50;
\! echo '#### WLM Queue Configuration'
SELECT wlm.service_class queue ,TRIM(wlm.name) queue_name ,LISTAGG(TRIM(cnd.condition), ', ') condition ,wlm.num_query_tasks query_concurrency ,wlm.query_working_mem per_query_memory_mb ,ROUND(((wlm.num_query_tasks*wlm.query_working_mem)::NUMERIC/mem.total_mem::NUMERIC)*100,0)::INT cluster_memory_pct ,wlm.max_execution_time ,wlm.user_group_wild_card ,wlm.query_group_wild_card FROM stv_wlm_service_class_config wlm JOIN stv_wlm_classification_config cnd ON wlm.service_class = cnd.action_service_class CROSS JOIN (SELECT SUM(num_query_tasks*query_working_mem) total_mem FROM pg_catalog.stv_wlm_service_class_config WHERE service_class > 5) mem WHERE wlm.service_class > 5 GROUP BY wlm.service_class ,TRIM(wlm.name) ,wlm.num_query_tasks ,wlm.query_working_mem ,mem.total_mem ,wlm.max_execution_time ,wlm.user_group_wild_card ,wlm.query_group_wild_card ORDER BY 1 ;
\! echo '#### WLM Query Management Rules (QMR)'
SELECT qmr.service_class queue ,TRIM(wlm.name) queue_name ,TRIM(rule_name) rule_name ,TRIM(action) AS action ,TRIM(metric_name)||' '||TRIM(metric_operator)||' '||metric_value AS rule FROM stv_wlm_qmr_config qmr JOIN stv_wlm_service_class_config wlm USING (service_class) WHERE qmr.service_class > 5 ORDER BY qmr.service_class,TRIM(rule_name);
\! echo '#### WLM Hourly Peak Concurrent Queries'
WITH generate_dt_series AS ( SELECT SYSDATE-(n*INTERVAL '5 second') AS dt FROM (SELECT ROW_NUMBER() OVER () AS n FROM stl_scan LIMIT 120960) ), apex AS ( SELECT iq.dt, iq.service_class, iq.num_query_tasks, COUNT(iq.slot_count) AS service_class_queries, SUM(iq.slot_count) AS service_class_slots FROM (SELECT gds.dt, wq.service_class, wscc.num_query_tasks, wq.slot_count FROM stl_wlm_query wq JOIN stv_wlm_service_class_config wscc ON (wscc.service_class = wq.service_class AND wscc.service_class > 4) JOIN generate_dt_series gds ON (wq.service_class_start_time <= gds.dt AND wq.service_class_end_time > gds.dt) WHERE wq.userid > 1 AND wq.service_class > 4) iq GROUP BY iq.dt, iq.service_class, iq.num_query_tasks ), maxes AS ( SELECT apex.service_class, trunc(apex.dt) AS d, to_char(apex.dt,'HH24') AS dt_h, MAX(service_class_slots) max_service_class_slots FROM apex GROUP BY apex.service_class, apex.dt, to_char(apex.dt,'HH24') ), apexes AS ( SELECT apex.service_class, apex.num_query_tasks AS max_wlm_concurrency, maxes.d AS day, maxes.dt_h || ':00 - ' || maxes.dt_h || ':59' AS hour, MAX(apex.service_class_slots) AS max_service_class_slots FROM apex JOIN maxes ON (apex.service_class = maxes.service_class AND apex.service_class_slots = maxes.max_service_class_slots) GROUP BY apex.service_class, apex.num_query_tasks, maxes.d, maxes.dt_h ORDER BY apex.service_class, maxes.d, maxes.dt_h ) SELECT service_class ,"hour" ,MAX(CASE WHEN "day" = DATE_TRUNC('day',GETDATE()) THEN max_service_class_slots ELSE NULL END) today ,MAX(CASE WHEN "day" = DATE_TRUNC('day',GETDATE())-1 THEN max_service_class_slots ELSE NULL END) yesterday ,MAX(CASE WHEN "day" = DATE_TRUNC('day',GETDATE())-2 THEN max_service_class_slots ELSE NULL END) two_days_ago ,MAX(CASE WHEN "day" = DATE_TRUNC('day',GETDATE())-3 THEN max_service_class_slots ELSE NULL END) three_days_ago ,MAX(CASE WHEN "day" = DATE_TRUNC('day',GETDATE())-4 THEN max_service_class_slots ELSE NULL END) four_days_ago ,MAX(CASE WHEN "day" = DATE_TRUNC('day',GETDATE())-5 THEN max_service_class_slots ELSE NULL END) five_days_ago ,MAX(CASE WHEN "day" = DATE_TRUNC('day',GETDATE())-6 THEN max_service_class_slots ELSE NULL END) six_days_ago FROM apexes GROUP BY service_class ,"hour" ORDER BY service_class ,"hour" ;
\! echo '#### QMR Rule Candidates - By Service Class'
WITH qmr AS ( SELECT service_class, 'query_cpu_time' ::VARCHAR(30) qmr_metric, MEDIAN(query_cpu_time ) p50, PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY query_cpu_time ) p99, MAX(query_cpu_time ) pmax FROM svl_query_metrics_summary WHERE userid > 1 GROUP BY 1 UNION ALL SELECT service_class, 'query_blocks_read' ::VARCHAR(30) qmr_metric, MEDIAN(query_blocks_read ) p50, PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY query_blocks_read ) p99, MAX(query_blocks_read ) pmax FROM svl_query_metrics_summary WHERE userid > 1 GROUP BY 1 UNION ALL SELECT service_class, 'query_execution_time' ::VARCHAR(30) qmr_metric, MEDIAN(query_execution_time ) p50, PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY query_execution_time ) p99, MAX(query_execution_time ) pmax FROM svl_query_metrics_summary WHERE userid > 1 GROUP BY 1 UNION ALL SELECT service_class, 'query_cpu_usage_percent' ::VARCHAR(30) qmr_metric, MEDIAN(query_cpu_usage_percent ) p50, PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY query_cpu_usage_percent ) p99, MAX(query_cpu_usage_percent ) pmax FROM svl_query_metrics_summary WHERE userid > 1 GROUP BY 1 UNION ALL SELECT service_class, 'query_temp_blocks_to_disk' ::VARCHAR(30) qmr_metric, MEDIAN(query_temp_blocks_to_disk ) p50, PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY query_temp_blocks_to_disk ) p99, MAX(query_temp_blocks_to_disk ) pmax FROM svl_query_metrics_summary WHERE userid > 1 GROUP BY 1 UNION ALL SELECT service_class, 'segment_execution_time' ::VARCHAR(30) qmr_metric, MEDIAN(segment_execution_time ) p50, PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY segment_execution_time ) p99, MAX(segment_execution_time ) pmax FROM svl_query_metrics_summary WHERE userid > 1 GROUP BY 1 UNION ALL SELECT service_class, 'cpu_skew' ::VARCHAR(30) qmr_metric, MEDIAN(cpu_skew ) p50, PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY cpu_skew ) p99, MAX(cpu_skew ) pmax FROM svl_query_metrics_summary WHERE userid > 1 GROUP BY 1 UNION ALL SELECT service_class, 'io_skew' ::VARCHAR(30) qmr_metric, MEDIAN(io_skew ) p50, PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY io_skew ) p99, MAX(io_skew ) pmax FROM svl_query_metrics_summary WHERE userid > 1 GROUP BY 1 UNION ALL SELECT service_class, 'scan_row_count' ::VARCHAR(30) qmr_metric, MEDIAN(scan_row_count ) p50, PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY scan_row_count ) p99, MAX(scan_row_count ) pmax FROM svl_query_metrics_summary WHERE userid > 1 GROUP BY 1 UNION ALL SELECT service_class, 'join_row_count' ::VARCHAR(30) qmr_metric, MEDIAN(join_row_count ) p50, PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY join_row_count ) p99, MAX(join_row_count ) pmax FROM svl_query_metrics_summary WHERE userid > 1 GROUP BY 1 UNION ALL SELECT service_class, 'nested_loop_join_row_count'::VARCHAR(30) qmr_metric, MEDIAN(nested_loop_join_row_count) p50, PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY nested_loop_join_row_count) p99, MAX(nested_loop_join_row_count) pmax FROM svl_query_metrics_summary WHERE userid > 1 GROUP BY 1 UNION ALL SELECT service_class, 'return_row_count' ::VARCHAR(30) qmr_metric, MEDIAN(return_row_count ) p50, PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY return_row_count ) p99, MAX(return_row_count ) pmax FROM svl_query_metrics_summary WHERE userid > 1 GROUP BY 1 UNION ALL SELECT service_class, 'spectrum_scan_row_count' ::VARCHAR(30) qmr_metric, MEDIAN(spectrum_scan_row_count ) p50, PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY spectrum_scan_row_count ) p99, MAX(spectrum_scan_row_count ) pmax FROM svl_query_metrics_summary WHERE userid > 1 GROUP BY 1 UNION ALL SELECT service_class, 'spectrum_scan_size_mb' ::VARCHAR(30) qmr_metric, MEDIAN(spectrum_scan_size_mb ) p50, PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY spectrum_scan_size_mb ) p99, MAX(spectrum_scan_size_mb ) pmax FROM svl_query_metrics_summary WHERE userid > 1 GROUP BY 1 ) SELECT service_class ,qmr_metric,p50,p99,pmax ,(LEFT(p99,1)::INT+1)*POWER(10,LENGTH((p99/10)::BIGINT)) qmr_rule ,ROUND(pmax/((LEFT(p99,1)::INT+1)*POWER(10,LENGTH((p99/10)::BIGINT))),2) pmax_magnitude ,ROW_NUMBER() OVER (PARTITION BY service_class ORDER BY (NVL(pmax,1)/((LEFT(p99,1)::INT+1)*POWER(10,LENGTH((p99/10)::BIGINT)))) DESC) rule_order FROM qmr WHERE NVL(p99,0) >= 10 AND (NVL(p50,0) + NVL(p99,0)) < NVL(pmax,0) AND ((LEFT(p99,1)::INT+1)*POWER(10,LENGTH((p99/10)::BIGINT))) < NVL(pmax,0) ORDER BY 1,8 ;
\! echo '#### Copy Performance Per Table'
SELECT a.endtime::date,a.tbl,trim(c.nspname) as "schema", trim(b.relname) as "tablename", sum(a.rows_inserted) as "rows_inserted", sum(d.distinct_files) as files_scanned, sum(d.MB_scanned) as MB_scanned, (sum(d.distinct_files)::numeric(19,3)/count(distinct a.query)::numeric(19,3))::numeric(19,3) as avg_files_per_copy, (sum(d.MB_scanned)/sum(d.distinct_files)::numeric(19,3))::numeric(19,3) as avg_file_size_mb, count(distinct a.query) no_of_copy, max(a.query) as sample_query , (sum(d.MB_scanned)*1024*1000000/SUM(d.load_micro)) as scan_rate_kbps, (sum(a.rows_inserted)*1000000/SUM(a.insert_micro)) as insert_rate_rows_ps from ( select query, tbl, sum(rows) as rows_inserted, max(endtime) as endtime, datediff('microsecond',min(starttime),max(endtime)) as insert_micro from stl_insert group by query, tbl) a, pg_class b, pg_namespace c , (select b.query, count(distinct b.bucket||b.key) as distinct_files, sum(b.transfer_size)/1024/1024 as MB_scanned, sum(b.transfer_time) as load_micro from stl_s3client b where b.http_method = 'GET' group by b.query) d where a.tbl = b.oid and b.relnamespace = c.oid and d.query = a.query group by 1,2,3,4 order by 1 desc, 5 desc, 3,4 LIMIT 50;
\! echo '#### Copy Time Spent on Compression and Statistics'
SELECT MAX(a.query) last_query ,MAX(a.xid) last_xid ,COUNT(*) load_count ,ROUND(SUM(COALESCE(b.comp_time, 0)) / 1000.00, 0) compression_secs ,ROUND(SUM(COALESCE(a.copy_time, 0)) / 1000.00, 0) copy_load_secs ,ROUND(SUM(COALESCE(c.analyze_time, 0)) / 1000.00, 0) analyse_secs ,SUBSTRING(q.querytxt, 1, 150) FROM ( SELECT query ,xid ,datediff(ms, starttime, endtime) copy_time FROM stl_query q WHERE (querytxt ilike 'copy %from%') AND EXISTS ( SELECT 1 FROM stl_commit_stats cs WHERE cs.xid = q.xid ) AND EXISTS ( SELECT xid FROM stl_query WHERE query IN ( SELECT DISTINCT query FROM stl_load_commits ) ) ) a LEFT JOIN ( SELECT xid ,SUM(datediff(ms, starttime, endtime)) comp_time FROM stl_query q WHERE ( querytxt LIKE 'COPY ANALYZE %' OR querytxt LIKE 'analyze compression phase %' ) AND EXISTS ( SELECT 1 FROM stl_commit_stats cs WHERE cs.xid = q.xid ) AND EXISTS ( SELECT xid FROM stl_query WHERE query IN ( SELECT DISTINCT query FROM stl_load_commits ) ) GROUP BY 1 ) b ON b.xid = a.xid LEFT JOIN ( SELECT xid ,SUM(datediff(ms, starttime, endtime)) analyze_time FROM stl_query q WHERE (querytxt LIKE 'padb_fetch_sample%') AND EXISTS ( SELECT 1 FROM stl_commit_stats cs WHERE cs.xid = q.xid ) AND EXISTS ( SELECT xid FROM stl_query WHERE query IN ( SELECT DISTINCT query FROM stl_load_commits ) ) GROUP BY 1 ) c ON c.xid = a.xid INNER JOIN stl_query q ON q.query = a.query WHERE (b.comp_time IS NOT NULL) OR (c.analyze_time > a.copy_time) GROUP BY SUBSTRING(q.querytxt, 1, 150) ORDER BY (ROUND(SUM(COALESCE(b.comp_time, 0)) / 1000.00, 0) + ROUND(SUM(COALESCE(a.copy_time, 0)) / 1000.00, 0) + ROUND(SUM(COALESCE(c.analyze_time, 0)) / 1000.00, 0)) DESC LIMIT 50;
 